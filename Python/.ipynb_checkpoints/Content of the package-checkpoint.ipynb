{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing multiple classifiers through Bayesian analysis\n",
    "\n",
    "This is the Python implementation of Bayesian tests to compare the performance of classifiers (more in general algorithms) assessed  via cross-validation.\n",
    "The package `bayesiantests` includes the following tests:\n",
    "* `correlated_ttest`  performs the correlated t-test on the performance of two classifiers that have been assessed by $m$-runs of $k$-fold cross-validation  on the same dataset. It return probabilities that, based on the measured performance, one model is better than another or vice versa or they are within the region of practical equivalence\n",
    "* `signtest` computes the probabilities that, based on the measured performance, one classifier is better than another or vice versa or they are within the region of practical equivalence\n",
    "* `signrank` computes the Bayesian equivalent of the Wilcoxon signed-rank test. It return probabilities that, based on the measured performance, one model is better than another or vice versa or they are within the region of practical equivalence.\n",
    "* `hierarchical` compares the performance of two classifiers that have been assessed by *m*-runs of *k*-fold cross-validation on *q* datasets by using a bayesian hierarchical model.\n",
    "\n",
    "We have written three notebooks that explain how to use these tests. Moreover, the notebook `The importance of the Rope` discusses with an example the importance of setting a region of practical equivalence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
